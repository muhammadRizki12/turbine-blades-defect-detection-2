{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50962ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "from keras.layers import (Conv2D, MaxPooling2D, BatchNormalization, Input, Activation)\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.applications import ResNet50, VGG16\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eef1257",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (256, 256)\n",
    "# ROOT_DIR = \"datasets/dataset_split\"\n",
    "ROOT_DIR = \"/kaggle/input/turbine-blades-2/datasets/dataset_split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c2619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengambil nama-nama kelas dari direktori\n",
    "CLASS_NAMES = ['ablation', 'breakdown', 'fracture', 'groove']\n",
    "\n",
    "# Membuat mapping dari nama kelas ke indeks\n",
    "CLASS_TO_INDEX = {name: index for index, name in enumerate(CLASS_NAMES)}\n",
    "\n",
    "# Menghitung jumlah kelas\n",
    "NUM_CLASSES = len(CLASS_NAMES) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b832d",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe586a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_mask(image_path, mask_path):\n",
    "    # Gambar dibaca, di-decode, dan di-resize (format PNG).\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    # Standardisasi ke rentang 0.0 - 1.0\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "\n",
    "    # Mask dibaca, di-decode, dan di-resize.\n",
    "    msk = tf.io.read_file(mask_path)\n",
    "    msk = tf.image.decode_png(msk, channels=1)\n",
    "    msk = tf.image.resize(msk, IMG_SIZE, method='nearest')\n",
    "    msk = tf.cast(msk, tf.int32)  # pastikan integer\n",
    "    \n",
    "    # Ubah mask ke one-hot sesuai NUM_CLASSES\n",
    "    msk = tf.squeeze(msk, axis=-1)\n",
    "    msk = tf.one_hot(msk, depth=NUM_CLASSES)\n",
    "    return img, msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6311f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(split_dir, batch_size=8, shuffle=True):\n",
    "    img_dir = os.path.join(split_dir, 'images')\n",
    "    mask_dir = os.path.join(split_dir, 'masks')\n",
    "    img_files = set([\n",
    "        f for f in os.listdir(img_dir)\n",
    "        if not (f.startswith('.') or f.startswith('._')) and f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ])\n",
    "    mask_files = set([\n",
    "        f for f in os.listdir(mask_dir)\n",
    "        if not (f.startswith('.') or f.startswith('._')) and f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ])\n",
    "    common_files = sorted(list(img_files & mask_files))\n",
    "    img_paths = [os.path.join(img_dir, f) for f in common_files]\n",
    "    mask_paths = [os.path.join(mask_dir, f) for f in common_files]\n",
    "    print(f\"Jumlah data di {split_dir}: {len(img_paths)}\")\n",
    "    assert len(img_paths) == len(mask_paths), f\"Jumlah gambar ({len(img_paths)}) dan mask ({len(mask_paths)}) tidak sama!\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((img_paths, mask_paths))\n",
    "    dataset = dataset.map(load_image_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if shuffle:\n",
    "        dataset = dataset.shuffle(100, seed=42)\n",
    "    return dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83045b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "train_ds = get_dataset(f'{ROOT_DIR}/train', batch_size=4,shuffle=True)\n",
    "val_ds = get_dataset(f'{ROOT_DIR}/val', batch_size=4, shuffle=False)\n",
    "test_ds = get_dataset(f'{ROOT_DIR}/test', batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0ec8d2",
   "metadata": {},
   "source": [
    "# Arsitektur"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e72326a",
   "metadata": {},
   "source": [
    "## U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92bfb8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_tensor, num_filters):\n",
    "    \"\"\"Blok konvolusi ganda yang menjadi dasar U-Net.\"\"\"\n",
    "    # Lapisan konvolusi pertama\n",
    "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    # Lapisan konvolusi kedua\n",
    "    x = Conv2D(num_filters, (3, 3), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    return x\n",
    "\n",
    "def unet(input_size=(256, 256, 3), num_classes=NUM_CLASSES):\n",
    "    inputs = Input(input_size)  \n",
    "\n",
    "    # --- ENCODER (JALUR KONTRAKSI) ---\n",
    "    # Blok 1\n",
    "    s1 = conv_block(inputs, 64)\n",
    "    p1 = layers.MaxPooling2D((2, 2))(s1)\n",
    "    \n",
    "    # Blok 2\n",
    "    s2 = conv_block(p1, 128)\n",
    "    p2 = layers.MaxPooling2D((2, 2))(s2)\n",
    "\n",
    "    # Blok 3\n",
    "    s3 = conv_block(p2, 256)\n",
    "    p3 = layers.MaxPooling2D((2, 2))(s3)\n",
    "\n",
    "    # Blok 4\n",
    "    s4 = conv_block(p3, 512)\n",
    "    p4 = layers.MaxPooling2D((2, 2))(s4)\n",
    "\n",
    "    # --- BOTTLENECK ---\n",
    "    b1 = conv_block(p4, 1024)\n",
    "\n",
    "    # --- DECODER (JALUR EKSPANSI) ---\n",
    "    # Blok 6\n",
    "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding=\"same\")(b1)\n",
    "    # Menggabungkan dengan skip connection dari Blok 4 Encoder\n",
    "    c6 = layers.concatenate([u6, s4])\n",
    "    s6 = conv_block(c6, 512)\n",
    "    \n",
    "    # Blok 7\n",
    "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding=\"same\")(s6)\n",
    "    # Menggabungkan dengan skip connection dari Blok 3 Encoder\n",
    "    c7 = layers.concatenate([u7, s3])\n",
    "    s7 = conv_block(c7, 256)\n",
    "\n",
    "    # Blok 8\n",
    "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding=\"same\")(s7)\n",
    "    # Menggabungkan dengan skip connection dari Blok 2 Encoder\n",
    "    c8 = layers.concatenate([u8, s2])\n",
    "    s8 = conv_block(c8, 128)\n",
    "    \n",
    "    # Blok 9\n",
    "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\")(s8)\n",
    "    # Menggabungkan dengan skip connection dari Blok 1 Encoder\n",
    "    c9 = layers.concatenate([u9, s1])\n",
    "    s9 = conv_block(c9, 64)\n",
    "\n",
    "    conv10 = Conv2D(num_classes, (1, 1), activation='softmax')(s9)\n",
    "\n",
    "    return Model(inputs=[inputs], outputs=[conv10], name='UNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd37355b",
   "metadata": {},
   "source": [
    "## U-Net 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f641a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Conv2DTranspose, concatenate\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cd2952",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size):\n",
    "    # first layer\n",
    "    x = Conv2D(n_filters, (kernel_size, kernel_size), padding = 'same', kernel_initializer = 'he_normal')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # second layer\n",
    "    x = Conv2D(n_filters, kernel_size, padding = 'same', kernel_initializer = 'he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f005aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_2(n_filters=16, dropout_prob=0.5, kernel_size=3, num_classes=NUM_CLASSES):\n",
    "    input_img = Input((256, 256, 3))\n",
    "\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters, kernel_size)\n",
    "    p1 = MaxPooling2D(pool_size = (2, 2))(c1)\n",
    "    p1 = Dropout(0.5 * dropout_prob)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, 2 * n_filters, kernel_size)\n",
    "    p2 = MaxPooling2D(pool_size = (2, 2))(c2)\n",
    "    p2 = Dropout(dropout_prob)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, 4 * n_filters, kernel_size)\n",
    "    p3 = MaxPooling2D(pool_size = (2, 2))(c3)\n",
    "    p3 = Dropout(dropout_prob)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, 8 * n_filters, kernel_size)\n",
    "    p4 = MaxPooling2D(pool_size = (2, 2))(c4)\n",
    "    p4 = Dropout(dropout_prob)(p4)\n",
    "\n",
    "    c5 = conv2d_block(p4, 16 * n_filters, kernel_size)\n",
    "\n",
    "    # Expansive path\n",
    "    u6 = Conv2DTranspose(8 * n_filters, (kernel_size, kernel_size), padding = 'same', strides = (2, 2))(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout_prob)(u6)\n",
    "    c6 = conv2d_block(u6, 8 * n_filters, kernel_size)\n",
    "\n",
    "    u7 = Conv2DTranspose(4 * n_filters, (kernel_size, kernel_size), padding = 'same', strides = (2, 2))(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout_prob)(u7)\n",
    "    c7 = conv2d_block(u7, 4 * n_filters, kernel_size)\n",
    "\n",
    "    u8 = Conv2DTranspose(2 * n_filters, (kernel_size, kernel_size), padding = 'same', strides = (2, 2))(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout_prob)(u8)\n",
    "    c8 = conv2d_block(u8, 2 * n_filters, kernel_size)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters, (kernel_size, kernel_size), padding = 'same', strides = (2, 2))(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout_prob)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters, kernel_size)\n",
    "\n",
    "    # Lapisan output yang dimodifikasi untuk 4 kelas\n",
    "    outputs = Conv2D(num_classes, 1, activation = 'softmax')(c9)\n",
    "\n",
    "    model = Model(inputs=[input_img], outputs=[outputs], name=\"UNet2\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27906a65",
   "metadata": {},
   "source": [
    "## Recurrent U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d87a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurrent_conv_block(inputs, filters, kernel_size=(3, 3), t=2):\n",
    "    \"\"\"\n",
    "    Recurrent Convolution Block: applies recurrent convolution t times.\n",
    "    \"\"\"\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    for i in range(t):\n",
    "        x = layers.Conv2D(filters, kernel_size, padding='same')(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44afff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rec_unet(input_size=(256, 256, 3), t=2, num_classes=NUM_CLASSES):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = recurrent_conv_block(inputs, 32, t=t)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = recurrent_conv_block(pool1, 64, t=t)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = recurrent_conv_block(pool2, 128, t=t)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = recurrent_conv_block(pool3, 256, t=t)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    # Middle\n",
    "    conv5 = recurrent_conv_block(pool4, 512, t=t)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = layers.concatenate([layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = recurrent_conv_block(up6, 256, t=t)\n",
    "\n",
    "    up7 = layers.concatenate([layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = recurrent_conv_block(up7, 128, t=t)\n",
    "\n",
    "    up8 = layers.concatenate([layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = recurrent_conv_block(up8, 64, t=t)\n",
    "\n",
    "    up9 = layers.concatenate([layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = recurrent_conv_block(up9, 32, t=t)\n",
    "\n",
    "    conv10 = Conv2D(num_classes, (1, 1), activation='softmax')(conv9)\n",
    "\n",
    "    return Model(inputs=[inputs], outputs=[conv10], name='rec_unet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4453e2e2",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6849cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters):\n",
    "    x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2D(filters, (3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def resnet50_unet(input_size=(256, 256, 3), num_classes=NUM_CLASSES):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Load ResNet50 encoder backbone\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=inputs)\n",
    "\n",
    "    # Ambil beberapa layer penting untuk skip connection\n",
    "    skip1 = base_model.get_layer(\"conv1_relu\").output       # 128x128\n",
    "    skip2 = base_model.get_layer(\"conv2_block3_out\").output # 64x64\n",
    "    skip3 = base_model.get_layer(\"conv3_block4_out\").output # 32x32\n",
    "    skip4 = base_model.get_layer(\"conv4_block6_out\").output # 16x16\n",
    "    bridge = base_model.get_layer(\"conv5_block3_out\").output # 8x8\n",
    "\n",
    "    # Decoder\n",
    "    up1 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(bridge)\n",
    "    up1 = layers.concatenate([up1, skip4])\n",
    "    up1 = conv_block(up1, 512)\n",
    "\n",
    "    up2 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(up1)\n",
    "    up2 = layers.concatenate([up2, skip3])\n",
    "    up2 = conv_block(up2, 256)\n",
    "\n",
    "    up3 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(up2)\n",
    "    up3 = layers.concatenate([up3, skip2])\n",
    "    up3 = conv_block(up3, 128)\n",
    "\n",
    "    up4 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(up3)\n",
    "    up4 = layers.concatenate([up4, skip1])\n",
    "    up4 = conv_block(up4, 64)\n",
    "\n",
    "    up5 = layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(up4)\n",
    "    up5 = conv_block(up5, 32)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(up5)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs, name='ResNet50_UNet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae72569c",
   "metadata": {},
   "source": [
    "## VGG16-Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c73b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs,filterCount):\n",
    "    x = Conv2D(filterCount,3,padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = Conv2D(filterCount,3,padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def decoder_block(inputs,skip_features,filter_count):\n",
    "    \n",
    "    x = layers.Conv2DTranspose(filter_count, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = layers.Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, filter_count)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848e4f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_vgg16(input_size=(256, 256, 3), num_classes=NUM_CLASSES):\n",
    "    inputs = Input(input_size)\n",
    "    print(inputs.shape)\n",
    "    vgg16 = VGG16(include_top=False,weights='imagenet',input_tensor = inputs)\n",
    "    #vgg16.summary()\n",
    "    # the encoder \n",
    "    skip1 = vgg16.get_layer(\"block1_conv2\").output\n",
    "    print(skip1.shape)\n",
    "    skip2 = vgg16.get_layer(\"block2_conv2\").output\n",
    "    skip3 = vgg16.get_layer(\"block3_conv3\").output\n",
    "    skip4 = vgg16.get_layer(\"block4_conv3\").output\n",
    "    # the center\n",
    "    center = vgg16.get_layer(\"block5_conv3\").output\n",
    "    \n",
    "    # the decoder \n",
    "    \n",
    "    d1 = decoder_block(center,skip4,512)\n",
    "    d2 = decoder_block(d1,skip3,256)\n",
    "    d3 = decoder_block(d2,skip2,128)\n",
    "    d4 = decoder_block(d3,skip1,64)\n",
    "    #output\n",
    "    #conv1 = Conv2D(32,3,padding=\"same\")(d4)\n",
    "    #conv2 = Conv2D(16,3,padding=\"same\")(conv1)\n",
    "    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4)\n",
    "    model = Model(inputs, outputs, name=\"VGG16_U-Net\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3275486d",
   "metadata": {},
   "source": [
    "## Transformer Recurrent U-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81403fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate,\n",
    "    BatchNormalization, Activation, Add, LayerNormalization,\n",
    "    Dense, MultiHeadAttention, Reshape\n",
    ")\n",
    "\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815e009d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recurrent_block(x, filters, t=2):\n",
    "    for i in range(t):\n",
    "        if i == 0:\n",
    "            x1 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(x)\n",
    "        else:\n",
    "            x1 = Conv2D(filters, kernel_size=3, padding='same', activation='relu')(Add()([x, x1]))\n",
    "            x1 = BatchNormalization()(x1)\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7fe25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rcnn_block(x, filters, t=2):\n",
    "    x1 = recurrent_block(x, filters, t)\n",
    "    x2 = recurrent_block(x1, filters, t)\n",
    "    out = Add()([x, x2])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226db40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_block(x, num_heads=4, ff_dim=512):\n",
    "    B, H, W, C = x.shape\n",
    "    x_flat = Reshape((H * W, C))(x)\n",
    "\n",
    "    # LayerNorm + MHA\n",
    "    attn_input = LayerNormalization(epsilon=1e-6)(x_flat)\n",
    "    attn_output = MultiHeadAttention(num_heads=num_heads, key_dim=C // num_heads)(attn_input, attn_input)\n",
    "    x = x_flat + attn_output  # Residual connection\n",
    "\n",
    "    # FFN\n",
    "    ffn_input = LayerNormalization(epsilon=1e-6)(x)\n",
    "    ffn_output = Dense(ff_dim, activation='relu')(ffn_input)\n",
    "    ffn_output = Dense(C)(ffn_output)\n",
    "    x = x + ffn_output  # Residual connection\n",
    "\n",
    "    return Reshape((H, W, C))(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transunet_with_rcnn(input_size=(256, 256, 3), num_classes=NUM_CLASSES):\n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = rcnn_block(inputs, 32)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = rcnn_block(pool1, 64)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = rcnn_block(pool2, 128)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = rcnn_block(pool3, 256)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    # Bottleneck with Transformer\n",
    "    conv5 = rcnn_block(pool4, 512)\n",
    "    trans = transformer_block(conv5)\n",
    "\n",
    "    # Decoder\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(trans), conv4], axis=-1)\n",
    "    conv6 = rcnn_block(up6, 256)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=-1)\n",
    "    conv7 = rcnn_block(up7, 128)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=-1)\n",
    "    conv8 = rcnn_block(up8, 64)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=-1)\n",
    "    conv9 = rcnn_block(up9, 32)\n",
    "\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(conv9)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs, name=\"Transunet_RCL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd0fd8a",
   "metadata": {},
   "source": [
    "# Metrix dan Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b22b10",
   "metadata": {},
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64957c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = EarlyStopping(monitor='val_dsc', patience=10, mode='max',\n",
    "                              verbose=1, restore_best_weights=True, min_delta=1e-6)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_dsc', factor=0.5, patience=3, mode='max', verbose=2)\n",
    "# Callback untuk U-Net\n",
    "unet_checkpoint = ModelCheckpoint(\n",
    "    filepath='model/unet.keras',\n",
    "    monitor='val_dsc',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Callback untuk Recurrent U-Net\n",
    "r_unet_checkpoint = ModelCheckpoint(\n",
    "    filepath='model/recurrent_unet.keras',\n",
    "    monitor='val_dsc',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "resnet50_unet_checkpoint = ModelCheckpoint(\n",
    "    filepath='model/resnet50_unet.keras',\n",
    "    monitor='val_dsc',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "class PrintValDsc(Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_dsc = logs.get('val_dsc')\n",
    "        print(f\"Epoch {epoch+1}: val_dsc = {val_dsc} ({type(val_dsc)})\")\n",
    "        if val_dsc is None:\n",
    "            print(\"⚠️ WARNING: val_dsc is None!\")\n",
    "        elif isinstance(val_dsc, float) and (val_dsc != val_dsc):  # NaN check\n",
    "            print(\"⚠️ WARNING: val_dsc is NaN!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a344ef0",
   "metadata": {},
   "source": [
    "## Metrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0e2840",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "IMG_SIZE = (256, 256)  # atau sesuai ukuran kamu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc650408",
   "metadata": {},
   "source": [
    "### Dice coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd675fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsc(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Multi-class Dice Coefficient.\n",
    "    y_true, y_pred: shape (batch, H, W, C), one-hot encoded.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    \n",
    "    intersection = tf.reduce_sum(y_true * y_pred, axis=[0, 1, 2])\n",
    "    union = tf.reduce_sum(y_true + y_pred, axis=[0, 1, 2])\n",
    "    \n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(dice)\n",
    "\n",
    "# Dice Coefficient metric\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1\n",
    "    y_true = tf.keras.backend.flatten(y_true)\n",
    "    y_pred = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true * y_pred)\n",
    "    return (2. * (intersection + smooth)) / (tf.keras.backend.sum(y_true) + tf.keras.backend.sum(y_pred) + smooth)\n",
    "\n",
    "# def dice_coef_loss(y_true, y_pred):\n",
    "#     return (1-dice_coef(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2686882f",
   "metadata": {},
   "source": [
    "### Dice loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7a1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dsc(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b0bc37",
   "metadata": {},
   "source": [
    "### IOU Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f993457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_score(y_true, y_pred, smooth=1e-7):\n",
    "    y_true_f = tf.reshape(y_true, [-1, tf.shape(y_true)[-1]])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1, tf.shape(y_pred)[-1]])\n",
    "\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n",
    "    union = tf.reduce_sum(y_true_f + y_pred_f, axis=0) - intersection\n",
    "\n",
    "    iou = (intersection + smooth) / (union + smooth)\n",
    "    return tf.reduce_mean(iou)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0b1a4a",
   "metadata": {},
   "source": [
    "### Categorical focal loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951df440",
   "metadata": {},
   "source": [
    "#### Alpha calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1a4431",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_class_distribution(mask_dir, num_classes):\n",
    "    class_counts = np.zeros(num_classes, dtype=np.int64)\n",
    "\n",
    "    mask_files = [\n",
    "        f for f in os.listdir(mask_dir)\n",
    "        if not f.startswith('.') and f.lower().endswith(('.png', '.jpg', '.jpeg'))\n",
    "    ]\n",
    "\n",
    "    for fname in tqdm(mask_files, desc=\"Menghitung distribusi kelas\"):\n",
    "        path = os.path.join(mask_dir, fname)\n",
    "\n",
    "        # Load mask\n",
    "        mask = tf.io.read_file(path)\n",
    "        mask = tf.image.decode_png(mask, channels=1)\n",
    "        mask = tf.image.resize(mask, IMG_SIZE, method='nearest')\n",
    "        mask = tf.cast(mask, tf.int32).numpy().squeeze()\n",
    "\n",
    "        # Hitung pixel untuk tiap class\n",
    "        for i in range(num_classes):\n",
    "            class_counts[i] += np.sum(mask == i)\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "def compute_alpha_weights(class_counts):\n",
    "    total = np.sum(class_counts)\n",
    "    class_frequencies = class_counts / total\n",
    "    alpha = 1.0 / (class_frequencies + 1e-6)  # Hindari divide by zero\n",
    "    alpha /= np.max(alpha)  # Normalisasi agar max=1\n",
    "    return alpha.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6283b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dir = f\"{ROOT_DIR}/train/masks\"\n",
    "\n",
    "counts = calculate_class_distribution(mask_dir, NUM_CLASSES)\n",
    "alpha = compute_alpha_weights(counts)\n",
    "\n",
    "print(\"Distribusi kelas:\", counts)\n",
    "print(\"Alpha untuk focal loss:\", alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c50acdc",
   "metadata": {},
   "source": [
    "#### Focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a4605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Focal Loss for multi-class semantic segmentation.\n",
    "    gamma: focusing parameter (default 2.0)\n",
    "    alpha: balance parameter (can be scalar or list per class)\n",
    "    \"\"\"\n",
    "    def loss(y_true, y_pred):\n",
    "        # Clip predictions to prevent log(0)\n",
    "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1.0 - 1e-7)\n",
    "\n",
    "        # Calculate cross-entropy\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "\n",
    "        # Calculate focal loss components\n",
    "        weight = tf.pow(1 - y_pred, gamma)\n",
    "\n",
    "        if isinstance(alpha, (list, tuple)):\n",
    "            alpha_tensor = tf.constant(alpha, dtype=tf.float32)\n",
    "            alpha_factor = y_true * alpha_tensor\n",
    "        else:\n",
    "            alpha_factor = y_true * alpha\n",
    "\n",
    "        focal_loss = alpha_factor * weight * cross_entropy\n",
    "\n",
    "        # Sum over classes, mean over batch\n",
    "        return tf.reduce_mean(tf.reduce_sum(focal_loss, axis=-1))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e8cf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = categorical_focal_loss(gamma=2.0, alpha=[0.1, 0.3, 0.3, 0.3, 0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6181cb",
   "metadata": {},
   "source": [
    "### Jaccard Disctance Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b65a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_distance_loss(y_true, y_pred,smooth = 100):\n",
    "    intersection = tf.keras.backend.sum(tf.keras.backend.abs(y_true * y_pred), axis=-1)\n",
    "    sum_ = tf.keras.backend.sum(tf.keras.backend.abs(y_true) + tf.keras.backend.abs(y_pred), axis=-1)\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return (1 - jac) * smooth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b114c1",
   "metadata": {},
   "source": [
    "# Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f626b7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unet = unet()\n",
    "model_unet.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    # loss=categorical_crossentropy,\n",
    "    # loss=bce_dice_loss,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(),\n",
    "        dsc,\n",
    "        tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES, name='miou')\n",
    "    ]\n",
    ")\n",
    "    \n",
    "model_rec_unet = rec_unet()\n",
    "model_rec_unet.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    # loss=categorical_crossentropy,\n",
    "    # loss=bce_dice_loss,\n",
    "    loss=loss_fn,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(),\n",
    "        dsc,\n",
    "        tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES, name='miou')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf570f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_resnet50_unet = resnet50_unet()\n",
    "model_resnet50_unet.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    # loss=categorical_crossentropy,\n",
    "    # loss=bce_dice_loss,\n",
    "    # loss=loss_fn,\n",
    "    loss=jaccard_distance_loss,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        dsc,\n",
    "        tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES, name='miou')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91b8d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unet_2 = unet_2()\n",
    "model_unet_2.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    # optimizer=Adam(learning_rate=0.0055),\n",
    "    # loss=categorical_crossentropy,\n",
    "    # loss=bce_dice_loss,\n",
    "    loss=loss_fn,\n",
    "    # loss=jaccard_distance_loss,\n",
    "    # loss=dice_loss,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        dsc,\n",
    "        tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES, name='miou')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311494f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unet_vgg16 = unet_vgg16()\n",
    "model_unet_vgg16.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    # loss=categorical_crossentropy,\n",
    "    # loss=bce_dice_loss,\n",
    "    loss=loss_fn,\n",
    "    # loss=jaccard_distance_loss,\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(name='accuracy'),\n",
    "        dsc,\n",
    "        tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES, name='miou')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99456542",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073efb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = ['Background', 'ablation', 'breakdown', 'fracture', 'groove']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c876c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizePredictionCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, dataset, class_names=CLASS_NAMES, num_samples=3):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.class_names = CLASS_NAMES\n",
    "        self.num_samples = num_samples\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        # Ambil satu batch dari dataset\n",
    "        for imgs, masks in self.dataset.take(1):\n",
    "            preds = self.model.predict(imgs)\n",
    "            plt.figure(figsize=(self.num_samples * 4, 4))\n",
    "            for i in range(self.num_samples):\n",
    "                # Input image\n",
    "                plt.subplot(3, self.num_samples, i+1)\n",
    "                plt.imshow(imgs[i].numpy())\n",
    "                plt.axis('off')\n",
    "                plt.title('Input')\n",
    "                # Ground truth mask\n",
    "                plt.subplot(3, self.num_samples, self.num_samples + i + 1)\n",
    "                plt.imshow(np.argmax(masks[i].numpy(), axis=-1), cmap='tab20')\n",
    "                plt.axis('off')\n",
    "                plt.title('Ground Truth')\n",
    "                # Predicted mask\n",
    "                plt.subplot(3, self.num_samples, 2*self.num_samples + i + 1)\n",
    "                plt.imshow(np.argmax(preds[i], axis=-1), cmap='tab20')\n",
    "                plt.axis('off')\n",
    "                plt.title('Prediction')\n",
    "            plt.suptitle(f'Epoch {epoch+1}')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00011d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_cb = VisualizePredictionCallback(val_ds, class_names=CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ea69e0",
   "metadata": {},
   "source": [
    "## U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41da095c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_unet_2 = model_unet_2.fit(train_ds, validation_data=val_ds,\n",
    "#                     epochs=EPOCHS, callbacks=[earlystopping, reduce_lr, visualize_cb], verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56094f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_unet = model_unet.fit(train_ds, validation_data=val_ds,\n",
    "                    epochs=EPOCHS, callbacks=[earlystopping, reduce_lr, unet_checkpoint, visualize_cb], verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f421f8",
   "metadata": {},
   "source": [
    "## Recurrent U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ae0095",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_rec_unet = model_rec_unet.fit(train_ds, validation_data=val_ds,\n",
    "                    epochs=EPOCHS, callbacks=[earlystopping, reduce_lr, visualize_cb], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c6c4da",
   "metadata": {},
   "source": [
    "## Resnet 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc1fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_resnet50_unet = model_resnet50_unet.fit(train_ds, validation_data=val_ds,\n",
    "                    epochs=EPOCHS, callbacks=[earlystopping, reduce_lr], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3f8938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpan model ResNet50 U-Net ke format Keras (.keras)\n",
    "model_resnet50_unet.save(\"model/resnet50_unet_final.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a228bfe",
   "metadata": {},
   "source": [
    "# Grafik Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1b03b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, title=\"Training History\"):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['categorical_accuracy'], label='Train categorical_accuracy')\n",
    "    plt.plot(history.history['val_categorical_accuracy'], label='Val categorical_accuracy')\n",
    "    plt.title(f\"{title} - categorical_accuracy\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('categorical_accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Dice Coefficient\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['dsc'], label='Train dsc')\n",
    "    plt.plot(history.history['val_dsc'], label='Validation dsc')\n",
    "    plt.title(f\"{title} - Dice Coefficient\")\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('DSC')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "for history in [history_rec_unet]: \n",
    "    plot_training_history(history, title=history.model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e1cc6",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6920c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_iou_per_class(model, dataset, num_classes=NUM_CLASSES):\n",
    "    \"\"\"\n",
    "    Menghitung Mean IoU per kelas pada seluruh dataset.\n",
    "    \"\"\"\n",
    "    total_intersection = np.zeros(num_classes)\n",
    "    total_union = np.zeros(num_classes)\n",
    "\n",
    "    for images, masks in dataset:\n",
    "        preds = model.predict(images)\n",
    "        y_pred = np.argmax(preds, axis=-1).reshape(-1)\n",
    "        y_true = np.argmax(masks.numpy(), axis=-1).reshape(-1)  # or masks.numpy().reshape(-1) if already in int format\n",
    "        for c in range(num_classes):\n",
    "            true_c = (y_true == c)\n",
    "            pred_c = (y_pred == c)\n",
    "            intersection = np.logical_and(true_c, pred_c).sum()\n",
    "            union = np.logical_or(true_c, pred_c).sum()\n",
    "            total_intersection[c] += intersection\n",
    "            total_union[c] += union\n",
    "\n",
    "    mean_iou = np.divide(\n",
    "        total_intersection,\n",
    "        total_union,\n",
    "        out=np.zeros_like(total_intersection, dtype=np.float32),\n",
    "        where=total_union != 0\n",
    "    )\n",
    "    return mean_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a03bef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_unet.evaluate(test_ds)\n",
    "print(\"Test loss:\", results[0])\n",
    "print(\"Test categorical_accuracyt:\", results[1])\n",
    "print(\"Test dice_coef:\", results[2])\n",
    "print(\"Test miou:\", results[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9e40e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_rec_unet.evaluate(test_ds)\n",
    "print(\"Test loss:\", results[0])\n",
    "print(\"Test categorical_accuracyt:\", results[1])\n",
    "print(\"Test dice_coef:\", results[2])\n",
    "print(\"Test miou:\", results[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4686c109",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model_resnet50_unet.evaluate(test_ds)\n",
    "print(\"Test loss:\", results[0])\n",
    "print(\"Test categorical_accuracyt:\", results[1])\n",
    "print(\"Test dice_coef:\", results[2])\n",
    "print(\"Test miou:\", results[3])\n",
    "# print(\"Test iou_score:\", results[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0750c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_MAPPING = {\n",
    "    0: 'Background',\n",
    "    1: 'ablation',\n",
    "    2: 'breakdown',\n",
    "    3: 'fracture',\n",
    "    4: 'groove'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fae716c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh penggunaan:\n",
    "miou_per_class = mean_iou_per_class(model_unet, test_ds, num_classes=NUM_CLASSES)\n",
    "for idx, name in CLASS_MAPPING.items():\n",
    "    print(f\"Mean IoU for class '{name}': {miou_per_class[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886053d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh penggunaan:\n",
    "miou_per_class = mean_iou_per_class(model_rec_unet, test_ds, num_classes=NUM_CLASSES)\n",
    "for idx, name in CLASS_MAPPING.items():\n",
    "    print(f\"Mean IoU for class '{name}': {miou_per_class[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b1f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh penggunaan:\n",
    "miou_per_class = mean_iou_per_class(model_resnet50_unet, test_ds, num_classes=NUM_CLASSES)\n",
    "for idx, name in CLASS_MAPPING.items():\n",
    "    print(f\"Mean IoU for class '{name}': {miou_per_class[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcedc06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model_and_plot_confusion(model, dataset, class_names):\n",
    "    \"\"\"\n",
    "    Evaluasi model segmentasi:\n",
    "    - Menampilkan test loss, accuracy, dice coef, dan mIoU\n",
    "    - Menampilkan confusion matrix pixel-wise\n",
    "    \"\"\"\n",
    "\n",
    "    # Hitung confusion matrix pixel-wise\n",
    "    y_true_all, y_pred_all = [], []\n",
    "\n",
    "    for images, masks in dataset:\n",
    "        preds = model.predict(images)\n",
    "        y_pred = np.argmax(preds, axis=-1).flatten()\n",
    "        y_true = np.argmax(masks.numpy(), axis=-1).flatten()\n",
    "        y_true_all.extend(y_true)\n",
    "        y_pred_all.extend(y_pred)\n",
    "\n",
    "    cm = confusion_matrix(y_true_all, y_pred_all, labels=range(len(class_names)))\n",
    "\n",
    "    # Visualisasi confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.title('Confusion Matrix (Pixel-wise)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "      # Evaluasi model\n",
    "    print(classification_report(\n",
    "        y_true_all, y_pred_all,\n",
    "        target_names=class_names,\n",
    "        zero_division=0\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d022a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Background', 'ablation', 'breakdown', 'fracture', 'groove']\n",
    "evaluate_model_and_plot_confusion(model_rec_unet, test_ds, class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3403e05",
   "metadata": {},
   "source": [
    "# Visualisasi testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b792efb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_mask_on_image(image, mask, class_names, alpha=0.5):\n",
    "    \"\"\"\n",
    "    image: numpy array (H, W, 3), range [0, 1] or [0, 255]\n",
    "    mask: numpy array (H, W), berisi index kelas (0=background, dst)\n",
    "    class_names: list of str\n",
    "    alpha: transparansi overlay\n",
    "    \"\"\"\n",
    "    # Pastikan image dalam range [0, 1]\n",
    "    if image.max() > 1.0:\n",
    "        image = image / 255.0\n",
    "\n",
    "    # Buat colormap\n",
    "    cmap = plt.get_cmap('tab20', len(class_names))\n",
    "    mask_rgb = cmap(mask)[..., :3]  # Ambil RGB saja\n",
    "\n",
    "    # Overlay: background (0) tidak diwarnai\n",
    "    mask_bool = mask > 0\n",
    "    overlay = image.copy()\n",
    "    overlay[mask_bool] = (1 - alpha) * image[mask_bool] + alpha * mask_rgb[mask_bool]\n",
    "    return overlay\n",
    "\n",
    "# Contoh penggunaan di fungsi predict_and_visualize:\n",
    "def predict_and_visualize(model, image_path, input_size=(256, 256), class_names=None):\n",
    "    img = load_img(image_path, target_size=input_size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    img_input = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    pred_mask = model.predict(img_input)[0]  # shape: (H, W, C)\n",
    "    mask_argmax = np.argmax(pred_mask, axis=-1)  # shape: (H, W)\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    # Gambar asli\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Mask prediksi\n",
    "    plt.subplot(1, 3, 2)\n",
    "    if class_names is None:\n",
    "        class_names = [f\"Class {i}\" for i in range(pred_mask.shape[-1])]\n",
    "    cmap = plt.get_cmap('tab20', len(class_names))\n",
    "    im = plt.imshow(mask_argmax, cmap=cmap, vmin=0, vmax=len(class_names)-1)\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.axis(\"off\")\n",
    "    cbar = plt.colorbar(im, ticks=range(len(class_names)), fraction=0.046, pad=0.04)\n",
    "    cbar.ax.set_yticklabels(class_names)\n",
    "    plt.clim(-0.5, len(class_names)-0.5)\n",
    "\n",
    "    # Overlay\n",
    "    plt.subplot(1, 3, 3)\n",
    "    overlay = overlay_mask_on_image(img_array, mask_argmax, class_names, alpha=0.5)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(\"Overlay\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e243db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Overlay mask ke atas gambar asli\n",
    "def overlay_mask_on_image(image, mask, class_names, alpha=0.5):\n",
    "    if image.max() > 1.0:\n",
    "        image = image / 255.0\n",
    "\n",
    "    cmap = plt.get_cmap('tab20', len(class_names))\n",
    "    mask_rgb = cmap(mask)[..., :3]\n",
    "\n",
    "    mask_bool = mask > 0\n",
    "    overlay = image.copy()\n",
    "    overlay[mask_bool] = (1 - alpha) * image[mask_bool] + alpha * mask_rgb[mask_bool]\n",
    "    return overlay\n",
    "\n",
    "# Visualisasi image + mask (true), pred mask, image + pred mask\n",
    "def visualize_segmentation(image_array, pred_mask, true_mask=None, class_names=None):\n",
    "    if class_names is None:\n",
    "        num_classes = pred_mask.max() + 1 if true_mask is None else max(pred_mask.max(), true_mask.max()) + 1\n",
    "        class_names = [f\"Class {i}\" for i in range(num_classes)]\n",
    "\n",
    "    cmap = plt.get_cmap('tab20', len(class_names))\n",
    "    ncols = 3 if true_mask is not None else 2\n",
    "    plt.figure(figsize=(6 * ncols, 6))\n",
    "\n",
    "    if true_mask is not None:\n",
    "        plt.subplot(1, ncols, 1)\n",
    "        overlay_true = overlay_mask_on_image(image_array, true_mask, class_names, alpha=0.5)\n",
    "        plt.imshow(overlay_true)\n",
    "        plt.title(\"Image + True Mask\")\n",
    "        plt.axis(\"off\")\n",
    "        idx = 2\n",
    "    else:\n",
    "        idx = 1\n",
    "\n",
    "    plt.subplot(1, ncols, idx)\n",
    "    im = plt.imshow(pred_mask, cmap=cmap, vmin=0, vmax=len(class_names)-1)\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.axis(\"off\")\n",
    "    cbar = plt.colorbar(im, ticks=range(len(class_names)), fraction=0.046, pad=0.04)\n",
    "    cbar.ax.set_yticklabels(class_names)\n",
    "    plt.clim(-0.5, len(class_names)-0.5)\n",
    "\n",
    "    plt.subplot(1, ncols, idx + 1)\n",
    "    overlay_pred = overlay_mask_on_image(image_array, pred_mask, class_names, alpha=0.5)\n",
    "    plt.imshow(overlay_pred)\n",
    "    plt.title(\"Image + Predicted Mask\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Prediksi dan visualisasi\n",
    "def predict_and_visualize(model, image_path, input_size=(256, 256), class_names=None, true_mask=None):\n",
    "    img = load_img(image_path, target_size=input_size)\n",
    "    img_array = img_to_array(img) / 255.0\n",
    "    img_input = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "    pred_mask = model.predict(img_input)[0]  # (H, W, C)\n",
    "    pred_classes = np.argmax(pred_mask, axis=-1)  # (H, W)\n",
    "\n",
    "    visualize_segmentation(img_array, pred_classes, true_mask=true_mask, class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133dc121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_true_mask(mask_path, target_size):\n",
    "    mask = load_img(mask_path, target_size=target_size, color_mode=\"grayscale\")\n",
    "    mask_array = img_to_array(mask).squeeze().astype(np.uint8)  # shape: (H, W)\n",
    "    return mask_array\n",
    "\n",
    "# Direktori image dan mask\n",
    "image_dir = f\"{ROOT_DIR}/test/images\"\n",
    "mask_dir = f\"{ROOT_DIR}/test/masks\"\n",
    "\n",
    "for img_file in os.listdir(image_dir):\n",
    "    if img_file.endswith(\".jpg\") or img_file.endswith(\".png\"):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "\n",
    "        # Ganti ekstensi ke .png jika mask disimpan dalam .png\n",
    "        mask_file = os.path.splitext(img_file)[0] + \".png\"\n",
    "        mask_path = os.path.join(mask_dir, mask_file)\n",
    "\n",
    "        # Cek apakah file mask ada\n",
    "        if os.path.exists(mask_path):\n",
    "            true_mask = load_true_mask(mask_path, target_size=(256, 256))\n",
    "        else:\n",
    "            print(f\"WARNING: Mask not found for {img_file}, skipping true mask overlay.\")\n",
    "            true_mask = None\n",
    "\n",
    "        print(f\"Processing: {img_file}\")\n",
    "        predict_and_visualize(model_resnet50_unet, img_path, input_size=(256, 256),\n",
    "                              class_names=CLASS_NAMES + [\"Background\"], true_mask=true_mask)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
